---
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults

layout: home
title: Nishanth Anand
background: /images/home.jpg
---
<h2> Hello curious mind! </h2>
I am a third year Ph.D. student in Computer Science at <a style ="color: blue;" href="http://rl.cs.mcgill.ca/">RL Lab</a>, <a style="color:blue;" href="https://www.mcgill.ca/">McGill University</a> and <a style="color:blue;" href = "https://mila.quebec/">Mila</a>, Montreal, Canada. I work on Reinforcement Learning, both deep and non-deep. My research advisor is <a style="color:blue;" href = "https://en.wikipedia.org/wiki/Doina_Precup">Prof. Doina Precup</a>.

Before Ph.D., I completed my M.Sc. in computer science at McGill University and Mila. I worked as a Data Scientist at <a style="color:blue;" href="https://fractal.ai/">Fractal Analytics</a> for roughly two years before starting my masters. I went to <a style="color:blue;" href="https://www.pes.edu/">PES Institue of Technology</a>, Bengaluru, India for my bachelor's studies in telecommunication engineering.

My research focuses on building reinforcement learning agents that can efficiently propagate reward signal along the temporal axis. At first, it may seem trivial to write an algorithm that can learn to create a link between actions and rewards. But, it is painstakingly hard to do in practice. I hope to bridge the enormous gap between how humans seamlessly assign credit compared to the RL agents. I also draw excitement in developing reinforcement learning algorithms that can learn continually throughout its life as they are a step closer to human intelligence. Realising such systems, providing mathematical statements for the system’s behaviour, evaluating such systems practically are some of the open problems I’m thinking about. You can find more <a style="color:blue;" href="https://nishanthvanand.github.io/CV.pdf">here</a>.

Often, I ponder on several abstract questions like: what is natural intelligence? Is there a single algorithm that can imitate it? If there’s one, what kind of learning rule does it use? What structure does that algorithm have? And many more questions along these lines. If you have thoughts on these questions, share them with me on my email or Twitter.

I spend a good chunk of time sleeping, watching math and physics videos on YouTube. I also like to play video games, board games, and spend time with friends, family, and nature.