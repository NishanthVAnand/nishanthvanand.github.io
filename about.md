---
layout: page
permalink: /about/
background: /images/about.jpg
---

I am a third year Ph.D. student in Computer Science at <a href="https://www.mcgill.ca/">McGill University</a> and <a href = "https://mila.quebec/">Mila</a>, Montreal</a>, Canada</a>. I work on Reinforcement Learning, both deep and non-deep. My research advisor is <a href = "https://en.wikipedia.org/wiki/Doina_Precup">Prof. Doina Precup</a>.

Before Ph.D., I completed my M.Sc. in computer science at McGill University and Mila. I worked as a Data Scientist at <a href="https://fractal.ai/">Fractal Analytics</a> for roughly two years before starting my masters. I went to <a href="https://www.pes.edu/">PES Institue of Technology</a>, Bengaluru, India for my bachelor's studies in telecommunication engineering.

My research focuses on building reinforcement learning agents that can efficiently propagate reward signal along the temporal axis. At first, it may seem trivial to write an algorithm that can learn to create a link between actions and rewards. But, it is painstakingly hard to do it in practice. I hope to bridge the enormous gap between how humans seamlessly assign credit compared to the RL agents. I also draw excitement in developing reinforcement learning algorithms that can learn continually throughout its life as they are a step closer to human intelligence.

Often, I ponder on several abstract questions like: what is natural intelligence? Is there a single algorithm that can imitate it? If thereâ€™s one, what kind of learning rule does it use? What structure does that algorithm have? And many more along these lines. If you have thoughts on these questions, share them with me on my email or Twitter.

I spend a good chunk of time sleeping, watching math and physics videos on YouTube. I also like to play video games, board games, and spend time with nature.